{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdbd32b",
   "metadata": {},
   "source": [
    "# Introduction to Binary Classification with PyCaret\n",
    "\n",
    "https://www.kdnuggets.com/2021/12/introduction-binary-classification-pycaret.html\n",
    "\n",
    "*PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with few lines only. See how to use it for binary classification.*\n",
    "\n",
    "By Moez Ali, Founder & Author of PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530c9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pycaret\n",
    "# gave errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cebd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge pycaret \n",
    "# \"Proceed ([y]/n)?\" => ran in terminal to answer - seems to have worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f500b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.classification import *\n",
    "import numpy as np\n",
    "from pycaret.utils import check_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923246f",
   "metadata": {},
   "source": [
    "## 1.0 Introduction\n",
    "\n",
    "PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows. It is an end-to-end machine learning and model management tool that speeds up the experiment cycle exponentially and makes you more productive.\n",
    "\n",
    "https://www.pycaret.org/\n",
    "\n",
    "In comparison with the other open-source machine learning libraries, PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with few lines only. This makes experiments exponentially fast and efficient. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and a few more.\n",
    "\n",
    "The design and simplicity of PyCaret are inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more technical expertise.\n",
    "\n",
    "To learn more about PyCaret, you can check the official website or GitHub.\n",
    "\n",
    "https://www.github.com/pycaret/pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e072a",
   "metadata": {},
   "source": [
    "## 2.0 Tutorial Objective\n",
    "\n",
    "In this tutorial we will learn:\n",
    "\n",
    "- Getting Data: How to import data from the PyCaret repository\n",
    "\n",
    "- Setting up Environment: How to set up an experiment in PyCaret and get started with building classification models\n",
    "\n",
    "- Create Model: How to create a model, perform stratified cross-validation and evaluate classification metrics\n",
    "\n",
    "- Tune Model: How to automatically tune the hyper-parameters of a classification model\n",
    "\n",
    "- Plot Model: How to analyze model performance using various plots\n",
    "\n",
    "- Finalize Model: How to finalize the best model at the end of the experiment\n",
    "\n",
    "- Predict Model: How to make predictions on unseen data\n",
    "\n",
    "- Save/Load Model: How to save/load a model for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa39e84",
   "metadata": {},
   "source": [
    "## 3.0 Installing PyCaret\n",
    "\n",
    "Installation is easy and will only take a few minutes. PyCaret’s default installation from pip only installs hard dependencies as listed in the requirements.txt file.\n",
    "\n",
    "https://github.com/pycaret/pycaret/blob/master/requirements.txt\n",
    "\n",
    "```\n",
    "pip install pycaret\n",
    "```\n",
    "\n",
    "To install the full version:\n",
    "\n",
    "```\n",
    "pip install pycaret[full] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9853a",
   "metadata": {},
   "source": [
    "## 4.0 What is Binary Classification?\n",
    " \n",
    " \n",
    "Binary classification is a supervised machine learning technique where the goal is to predict categorical class labels which are discrete and unordered such as Pass/Fail, Positive/Negative, Default/Not-Default, etc. A few real-world use cases for classification are listed below:\n",
    "\n",
    "- Medical testing to determine if a patient has a certain disease or not\n",
    "    + the classification property is the presence of the disease\n",
    "\n",
    "- A “pass or fail” test method or quality control in factories, i.e. deciding if a specification has or has not been met\n",
    "    + a go/no-go classification\n",
    "\n",
    "- Information retrieval, namely deciding whether a page or an article should be in the result set of a search or not\n",
    "    + the classification property is the relevance of the article or the usefulness to the user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365ddbe",
   "metadata": {},
   "source": [
    "## 5.0 Overview of the Classification Module in PyCaret\n",
    "\n",
    "PyCaret’s classification module (`pycaret.classification`) is a supervised machine learning module that is used for classifying the elements into a binary group based on various techniques and algorithms. Some common use cases of classification problems include predicting customer default (yes or no), customer churn (customer will leave or stay), disease found (positive or negative).\n",
    "\n",
    "https://pycaret.readthedocs.io/en/latest/api/classification.html\n",
    "\n",
    "The PyCaret classification module can be used for Binary or Multi-class classification problems. It has over 18 algorithms and 14 plots to analyze the performance of models. Be it hyper-parameter tuning, ensembling, or advanced techniques like stacking, PyCaret’s classification module has it all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78294f5c",
   "metadata": {},
   "source": [
    "## 6.0 Dataset for the Tutorial\n",
    "\n",
    "For this tutorial, we will use a dataset from UCI called Default of Credit Card Clients Dataset. \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "This dataset contains information on default payments, demographic factors, credit data, payment history, and billing statements of credit card clients in Taiwan from April 2005 to September 2005. There are 24,000 samples and 25 features. Short descriptions of each column are as follows:\n",
    "\n",
    "- ID: ID of each client\n",
    "\n",
    "- LIMIT_BAL: Amount of given credit in NT dollars\n",
    "    + includes individual and family/supplementary credit\n",
    "\n",
    "- SEX: Gender\n",
    "    + 1 = male\n",
    "    + 2 = female\n",
    "\n",
    "- EDUCATION: \n",
    "    + 1 = graduate school\n",
    "    + 2 = university\n",
    "    + 3 = high school\n",
    "    + 4 = others\n",
    "    + 5 = unknown\n",
    "    + 6 = unknown\n",
    "\n",
    "- MARRIAGE: Marital status\n",
    "    + 1 = married\n",
    "    + 2 = single\n",
    "    + 3 = others\n",
    "\n",
    "- AGE: Age in years\n",
    "\n",
    "- PAY_0 to PAY_6: Repayment status by n months ago\n",
    "    + PAY_0 = last month\n",
    "    + ... \n",
    "    + PAY_6 = 6 months ago\n",
    "    + Labels: \n",
    "        - -1 = pay duly\n",
    "        - 1 = payment delay for one month\n",
    "        - 2 = payment delay for two months\n",
    "        - ...\n",
    "        - 8 = payment delay for eight months\n",
    "        - 9 = payment delay for nine months and above\n",
    "\n",
    "- BILL_AMT1 to BILL_AMT6: Amount of bill statement by n months ago\n",
    "    + BILL_AMT1 = last_month\n",
    "    + ...\n",
    "    + BILL_AMT6 = 6 months ago\n",
    "\n",
    "- PAY_AMT1 to PAY_AMT6: Amount of payment by n months ago\n",
    "    + BILL_AMT1 = last_month\n",
    "    + ... \n",
    "    + BILL_AMT6 = 6 months ago\n",
    "\n",
    "- default: Default payment - Target Column\n",
    "    + 1 = yes\n",
    "    + 0 = no\n",
    "\n",
    "Dataset Acknowledgement: Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30587d49",
   "metadata": {},
   "source": [
    "## 7.0 Getting the Data\n",
    "\n",
    "You can download the data from the original source found here \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n",
    "\n",
    "and load it using pandas (learn how) \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "\n",
    "or you can use PyCaret’s data repository to load the data using the get_data() function (This will require an internet connection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9876f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64400.0</td>\n",
       "      <td>57069.0</td>\n",
       "      <td>57608.0</td>\n",
       "      <td>19394.0</td>\n",
       "      <td>19619.0</td>\n",
       "      <td>20024.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1      90000    2          2         2   34      0      0      0      0   \n",
       "2      50000    2          2         1   37      0      0      0      0   \n",
       "3      50000    1          2         1   57     -1      0     -1      0   \n",
       "4      50000    1          1         2   37      0      0      0      0   \n",
       "\n",
       "   PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0     -2     -2     3913.0     3102.0      689.0        0.0        0.0   \n",
       "1      0      0    29239.0    14027.0    13559.0    14331.0    14948.0   \n",
       "2      0      0    46990.0    48233.0    49291.0    28314.0    28959.0   \n",
       "3      0      0     8617.0     5670.0    35835.0    20940.0    19146.0   \n",
       "4      0      0    64400.0    57069.0    57608.0    19394.0    19619.0   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0        0.0       0.0     689.0       0.0       0.0       0.0       0.0   \n",
       "1    15549.0    1518.0    1500.0    1000.0    1000.0    1000.0    5000.0   \n",
       "2    29547.0    2000.0    2019.0    1200.0    1100.0    1069.0    1000.0   \n",
       "3    19131.0    2000.0   36681.0   10000.0    9000.0     689.0     679.0   \n",
       "4    20024.0    2500.0    1815.0     657.0    1000.0    1000.0     800.0   \n",
       "\n",
       "   default  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "# from pycaret.datasets import get_data\n",
    "\n",
    "dataset = get_data('credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ffe7ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64400.0</td>\n",
       "      <td>57069.0</td>\n",
       "      <td>57608.0</td>\n",
       "      <td>19394.0</td>\n",
       "      <td>19619.0</td>\n",
       "      <td>20024.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1      90000    2          2         2   34      0      0      0      0   \n",
       "2      50000    2          2         1   37      0      0      0      0   \n",
       "3      50000    1          2         1   57     -1      0     -1      0   \n",
       "4      50000    1          1         2   37      0      0      0      0   \n",
       "\n",
       "   PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "0     -2     -2     3913.0     3102.0      689.0        0.0        0.0   \n",
       "1      0      0    29239.0    14027.0    13559.0    14331.0    14948.0   \n",
       "2      0      0    46990.0    48233.0    49291.0    28314.0    28959.0   \n",
       "3      0      0     8617.0     5670.0    35835.0    20940.0    19146.0   \n",
       "4      0      0    64400.0    57069.0    57608.0    19394.0    19619.0   \n",
       "\n",
       "   BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0        0.0       0.0     689.0       0.0       0.0       0.0       0.0   \n",
       "1    15549.0    1518.0    1500.0    1000.0    1000.0    1000.0    5000.0   \n",
       "2    29547.0    2000.0    2019.0    1200.0    1100.0    1069.0    1000.0   \n",
       "3    19131.0    2000.0   36681.0   10000.0    9000.0     689.0     679.0   \n",
       "4    20024.0    2500.0    1815.0     657.0    1000.0    1000.0     800.0   \n",
       "\n",
       "   default  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27124a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of data\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5dd30",
   "metadata": {},
   "source": [
    "In order to demonstrate the use of the `predict_model` function on unseen data, a sample of 1200 records (~5%) has been withheld from the original dataset to be used for predictions at the end. This should not be confused with a train-test-split, as this particular split is performed to simulate a real-life scenario. Another way to think about this is that these 1200 customers are not available at the time of training of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fc75d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Modeling: (22800, 24)\n",
      "Unseen Data For Predictions: (1200, 24)\n"
     ]
    }
   ],
   "source": [
    "# sample 5% of data to be used as unseen data\n",
    "data = dataset.sample(frac=0.95, random_state=786)\n",
    "data_unseen = dataset.drop(data.index)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "data_unseen.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# print the revised shape\n",
    "print('Data for Modeling: ' + str(data.shape))\n",
    "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6653a50",
   "metadata": {},
   "source": [
    "## 8.0 Setting up Environment in PyCaret\n",
    "\n",
    "The setup function in PyCaret initializes the environment and creates the transformation pipeline for modeling and deployment. setup must be called before executing any other function in pycaret. It takes two mandatory parameters: a pandas dataframe and the name of the target column. All other parameters are optional can be used to customize the preprocessing pipeline.\n",
    "\n",
    "When setup is executed, PyCaret's inference algorithm will automatically infer the data types for all features based on certain properties. The data type should be inferred correctly but this is not always the case. To handle this, PyCaret displays a prompt, asking for data types confirmation, once you execute the setup. You can press enter if all data types are correct or type quit to exit the setup.\n",
    "\n",
    "Ensuring that the data types are correct is really important in PyCaret as it automatically performs multiple type-specific preprocessing tasks which are imperative for machine learning models.\n",
    "\n",
    "Alternatively, you can also use `numeric_features` and `categorical_features` parameters in the setup to pre-define the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30feda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init setup\n",
    "# from pycaret.classification import *\n",
    "\n",
    "s = setup(data = data, target = 'default', session_id=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a8e55",
   "metadata": {},
   "source": [
    "png\n",
    "\n",
    "Once the setup has been successfully executed it displays the information grid which contains some important information about the experiment. Most of the information is related to the pre-processing pipeline which is constructed when setup is executed. The majority of these features are out of scope for this tutorial, however, a few important things to note are:\n",
    "\n",
    "- session_id: A pseudo-random number distributed as a seed in all functions for later reproducibility\n",
    "    + If no session_id is passed, a random number is automatically generated that is distributed to all functions\n",
    "    + In this experiment, the session_id is set as 123 for later reproducibility\n",
    "\n",
    "- Target Type: Binary or Multiclass\n",
    "    + The Target type is automatically detected and shown\n",
    "    + There is no difference in how the experiment is performed for Binary or Multiclass problems\n",
    "    + All functionalities are identical\n",
    "\n",
    "- Label Encoded: When the Target variable is of type string (i.e. ‘Yes’ or ‘No’) instead of 1 or 0, it automatically encodes the label into 1 and 0 and displays the mapping (0: No, 1: Yes) for reference\n",
    "    + In this experiment, no label encoding is required since the target variable is of type numeric\n",
    "\n",
    "- Original Data: Displays the original shape of the dataset\n",
    "    + In this experiment (22800, 24) means 22,800 samples and 24 features including the target column\n",
    "\n",
    "- Missing Values: When there are missing values in the original data this will show as True\n",
    "    + For this experiment, there are no missing values in the dataset\n",
    "\n",
    "- Numeric Features: The number of features inferred as numeric\n",
    "    + In this dataset, 14 out of 24 features are inferred as numeric\n",
    "\n",
    "- Categorical Features: The number of features inferred as categorical\n",
    "    + In this dataset, 9 out of 24 features are inferred as categorical\n",
    "\n",
    "- Transformed Train Set: Displays the shape of the transformed training set\n",
    "    + Notice that the original shape of (22800, 24) is transformed into (15959, 91) for the transformed train set and the number of features has increased to 91 from 24 due to one-hot-encoding\n",
    "\n",
    "- Transformed Test Set: Displays the shape of the transformed test/hold-out set\n",
    "    + There are 6841 samples in the test/hold-out set\n",
    "    + This split is based on the default value of 70/30 that can be changed using the train_size parameter in the setup\n",
    "\n",
    "Notice how a few tasks that are imperative to perform modeling are automatically handled such as missing value imputation (in this case there are no missing values in the training data, but we still need imputers for unseen data), categorical encoding, etc. Most of the parameters in the setup are optional and used for customizing the pre-processing pipeline. These parameters are out of scope for this tutorial but we will cover them in future tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1654a8",
   "metadata": {},
   "source": [
    "## 9.0 Comparing All Models\n",
    "\n",
    "Comparing all models to evaluate performance is the recommended starting point for modeling once the setup is completed (unless you exactly know what kind of model you need, which is often not the case). This function trains all models in the model library and scores them using stratified cross-validation for metric evaluation. The output prints a scoring grid that shows average Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC across the folds (10 by default) along with training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9977e8",
   "metadata": {},
   "source": [
    "The scoring grid printed above highlights the highest performing metric for comparison purposes only. The grid by default is sorted using Accuracy (highest to lowest) which can be changed by passing the sort parameter. For example `compare_models(sort = 'Recall')` will sort the grid by recall instead of accuracy.\n",
    "\n",
    "If you want to change the fold parameter from the default value of 10 to a different value then you can use the fold parameter. For example `compare_models(fold = 5)` will compare all models on 5 fold cross-validation. Reducing the number of folds will improve the training time. By default, `compare_models` return the best performing model based on default sort order but can be used to return a list of top N models by using n_select parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1316fa",
   "metadata": {},
   "source": [
    "```\n",
    "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=123, solver='auto', tol=0.001)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdf184",
   "metadata": {},
   "source": [
    "## 10.0 Create a Model\n",
    "\n",
    "`create_model` is the most granular function in PyCaret and is often the foundation behind most of the PyCaret functionalities. As the name suggests this function trains and evaluates a model using cross-validation that can be set with fold parameter. The output prints a scoring grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC by fold.\n",
    "\n",
    "For the remaining part of this tutorial, we will work with the below models as our candidate models. The selections are for illustration purposes only and do not necessarily mean they are the top-performing or ideal for this type of data.\n",
    "\n",
    "- Decision Tree Classifier (‘dt’)\n",
    "\n",
    "- K Neighbors Classifier (‘knn’)\n",
    "\n",
    "- Random Forest Classifier (‘rf’)\n",
    "\n",
    "There are 18 classifiers available in the model library of PyCaret. To see a list of all classifiers either check the documentation or use models function to see the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d084a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check available models\n",
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d665cb",
   "metadata": {},
   "source": [
    "### 10.1 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6721cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = create_model('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a599248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model object is stored in the variable 'dt' \n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8594df",
   "metadata": {},
   "source": [
    "```\n",
    "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=123, splitter='best')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b3270",
   "metadata": {},
   "source": [
    "### 10.2 K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292bdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = create_model('knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417af388",
   "metadata": {},
   "source": [
    "### 10.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cbb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a84108",
   "metadata": {},
   "source": [
    "Notice that the mean score of all models matches with the score printed in `compare_models`. This is because the metrics printed in the `compare_models` score grid are the average scores across all CV folds. Similar to the `compare_models`, if you want to change the fold parameter from the default value of 10 to a different value then you can use the `fold` parameter. For Example: `create_model('dt', fold = 5)` will create a Decision Tree Classifier using 5 fold stratified CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2fee9",
   "metadata": {},
   "source": [
    "## 11.0 Tune a Model\n",
    "\n",
    "When a model is created using the `create_model` function it uses the default hyperparameters to train the model. In order to tune hyperparameters, the `tune_model` function is used. This function automatically tunes the hyperparameters of a model using random grid search on a pre-defined search space. The output prints a scoring grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa, and MCC by fold for the best model. To use the custom search grid, you can pass `custom_grid` parameter in the tune_model function (see 11.2 KNN tuning below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7be2e3",
   "metadata": {},
   "source": [
    "### 11.1 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bcefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt = tune_model(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cf052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned model object is stored in the variable 'tuned_dt'. \n",
    "print(tuned_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeacb2c",
   "metadata": {},
   "source": [
    "```\n",
    "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy', max_depth=6, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.002, min_impurity_split=None, min_samples_leaf=5, min_samples_split=5, min_weight_fraction_leaf=0.0, presort='deprecated', random_state=123, splitter='best')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e9b990",
   "metadata": {},
   "source": [
    "### 11.2 K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "tuned_knn = tune_model(knn, custom_grid = {'n_neighbors' : np.arange(0,50,1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7332256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuned_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb1d83",
   "metadata": {},
   "source": [
    "```\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=-1, n_neighbors=42, p=2, weights='uniform')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61ebe1",
   "metadata": {},
   "source": [
    "### 11.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d480076",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf = tune_model(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72115c7",
   "metadata": {},
   "source": [
    "By default, `tune_model` optimizes `Accuracy` but this can be changed using `optimize` parameter. For example: `tune_model(dt, optimize = 'AUC')` will search for the hyperparameters of a Decision Tree Classifier that results in the highest `AUC` instead of `Accuracy`. For the purposes of this example, we have used the default metric Accuracy only for the sake of simplicity. Generally, when the dataset is imbalanced (such as the credit dataset we are working with) Accuracy is not a good metric for consideration. The methodology behind selecting the right metric to evaluate a classifier is beyond the scope of this tutorial but if you would like to learn more about it, you can click here to read an article on how to choose the right evaluation metric:\n",
    "\n",
    "https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\n",
    "\n",
    "Metrics alone are not the only criteria you should consider when finalizing the best model for production. Other factors to consider include training time, the standard deviation of kfolds, etc. As you progress through the tutorial series we will discuss those factors in detail at the intermediate and expert levels. For now, let’s move forward considering the Tuned Random Forest Classifier `tuned_rf`, as our best model for the remainder of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c81a6",
   "metadata": {},
   "source": [
    "## 12.0 Plot a Model\n",
    "\n",
    "Before model finalization, the `plot_model` function can be used to analyze the performance across different aspects such as AUC, confusion_matrix, decision boundary, etc. This function takes a trained model object and returns a plot based on the test set.\n",
    "\n",
    "There are 15 different plots available, please see the `plot_model` documentation for the list of available plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7ec29",
   "metadata": {},
   "source": [
    "### 12.1 AUC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_rf, plot = 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16b1e2",
   "metadata": {},
   "source": [
    "png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561b271",
   "metadata": {},
   "source": [
    "### 12.2 Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_rf, plot = 'pr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57425eff",
   "metadata": {},
   "source": [
    "png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6acac",
   "metadata": {},
   "source": [
    "### 12.3 Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e599a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_rf, plot='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965179c7",
   "metadata": {},
   "source": [
    "png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240bafd",
   "metadata": {},
   "source": [
    "### 12.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_rf, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2099cd5",
   "metadata": {},
   "source": [
    "png\n",
    "\n",
    "Another way to analyze the performance of models is to use the `evaluate_model()` function which displays a user interface for all of the available plots for a given model. It internally uses the `plot_model()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tuned_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89543c26",
   "metadata": {},
   "source": [
    "## 13.0 Predict on test / hold-out Sample\n",
    "\n",
    "Before finalizing the model, it is advisable to perform one final check by predicting the test/hold-out set and reviewing the evaluation metrics. If you look at the information grid in Section 8 above, you will see that 30%  (6,841 samples) of the data has been separated out as a test/hold-out sample. All of the evaluation metrics we have seen above are cross-validated results based on the training set (70%). Now, using our final trained model stored in the `tuned_rf` we will predict the test / hold-out sample and evaluate the metrics to see if they are materially different than the CV results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(tuned_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8869a",
   "metadata": {},
   "source": [
    "The accuracy on the test/hold-out set is 0.8116 compared to 0.8203 achieved on the `tuned_rf` CV results (in section 11.3 above). This is not a significant difference. If there is a large variation between the test/hold-out and CV results, then this would normally indicate over-fitting but could also be due to several other factors and would require further investigation. In this case, we will move forward with finalizing the model and predicting on unseen data (the 5% that we had separated in the beginning and never exposed to PyCaret).\n",
    "\n",
    "**TIP:** It’s always good to look at the standard deviation of CV results when using `create_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7ac02",
   "metadata": {},
   "source": [
    "## 14.0 Finalize Model for Deployment\n",
    "\n",
    "Model finalization is the last step in the experiment. A normal machine learning workflow in PyCaret starts with `setup`, followed by comparing all models using the `compare_models` and shortlisting a few candidate models (based on the metric of interest) to perform several modeling techniques such as hyperparameter tuning, ensembling, stacking, etc. This workflow will eventually lead you to the best model for use in making predictions on new and unseen data. The `finalize_model` function fits the model onto the complete dataset including the test/hold-out sample (30% in this case). The purpose of this function is to train the final model on the complete dataset before it is deployed in production. (This is optional, you may or may not use finalize_model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize rf model\n",
    "final_rf = finalize_model(tuned_rf)\n",
    "\n",
    "# print final model parameters\n",
    "print(final_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffa08e",
   "metadata": {},
   "source": [
    "```\n",
    "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={}, criterion='entropy', max_depth=5, max_features=1.0, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0002, min_impurity_split=None, min_samples_leaf=5, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=-1, oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
    "```\n",
    "\n",
    "**Caution:** One final word of caution. Once the model is finalized, the entire dataset including the test/hold-out set is used for training. As such, if the model is used for predictions on the hold-out set after `finalize_model` is used, the information grid printed will be misleading as you are trying to predict on the same data that was used for modeling. In order to demonstrate this point only, we will use `final_rf` under `predict_model` to compare the information grid with the one above in section 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0241c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(final_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b8c9f",
   "metadata": {},
   "source": [
    "Notice how the AUC in `final_rf` has increased to 0.7526 from 0.7407, even though the model is the same. This is because the `final_rf` variable has been trained on the complete dataset including the test/hold-out set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09604c",
   "metadata": {},
   "source": [
    "## 15.0 Predict on unseen data\n",
    "\n",
    "The `predict_model` function is also used to predict on the unseen dataset. The only difference from section 13 above is that this time we will pass the `data_unseen`. It is the variable created at the beginning of this tutorial and contains 5% (1200 samples) of the original dataset which was never exposed to PyCaret (see section 7 for explanation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions = predict_model(final_rf, data=data_unseen)\n",
    "unseen_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617da3be",
   "metadata": {},
   "source": [
    "png\n",
    "\n",
    "The `Label` and `Score` columns are added onto the `data_unseen` set. The label is the prediction and the score is the probability of the prediction. Notice that predicted results are concatenated to the original dataset while all the transformations are automatically performed in the background. You can also check the metrics on this since you have an actual target column `default` available. To do that we will use `pycaret.utils` module. See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check metric on unseen data\n",
    "# from pycaret.utils import check_metric\n",
    "\n",
    "check_metric(unseen_predictions['default'], unseen_predictions['Label'], metric = 'Accuracy')  # 0.8167"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d93e3c",
   "metadata": {},
   "source": [
    "## 16.0 Saving the model\n",
    "\n",
    "We have now finished the experiment by finalizing the `tuned_rf` model which is now stored in `final_rf` variable. We have also used the model stored in `final_rf` to predict `data_unseen`. This brings us to the end of our experiment, but one question is still to be asked: What happens when you have more new data to predict? Do you have to go through the entire experiment again? The answer is no, PyCaret's inbuilt function `save_model()` allows you to save the model along with the entire transformation pipeline for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d024e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the final model\n",
    "save_model(final_rf, 'Final RF Model 11Nov2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9112d50",
   "metadata": {},
   "source": [
    "```\n",
    "Transformation Pipeline and Model Successfully Saved\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a3669",
   "metadata": {},
   "source": [
    "## 17.0 Loading the saved model\n",
    "\n",
    "To load a saved model at a future date in the same or an alternative environment, we would use PyCaret’s `load_model()` function and then easily apply the saved model on new unseen data for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "saved_final_rf = load_model('Final RF Model 11Nov2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bfaf76",
   "metadata": {},
   "source": [
    "```\n",
    "Transformation Pipeline and Model Successfully Loaded\n",
    "``` \n",
    "\n",
    "Once the model is loaded in the environment, you can simply use it to predict on any new data using the same `predict_model()` function. Below we have applied the loaded model to predict the same `data_unseen` that we used in section 13 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e23161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on new data\n",
    "new_prediction = predict_model(saved_final_rf, data=data_unseen)\n",
    "new_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741a47b",
   "metadata": {},
   "source": [
    "png\n",
    "\n",
    "Notice that the results of `unseen_predictions` and `new_prediction` are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.utils import check_metric\n",
    "\n",
    "check_metric(new_prediction['default'], new_prediction['Label'], metric = 'Accuracy')  #  0.8167"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517a104f",
   "metadata": {},
   "source": [
    "## 18.0 Wrap-up / Next Steps?\n",
    "\n",
    "This tutorial has covered the entire machine learning pipeline from data ingestion, pre-processing, training the model, hyperparameter tuning, prediction, and saving the model for later use. We have completed all of these steps in less than 10 commands which are naturally constructed and very intuitive to remember such as:\n",
    "\n",
    "- `create_model()`\n",
    "\n",
    "- `tune_model()`\n",
    "\n",
    "- `compare_models()`\n",
    "\n",
    "Re-creating the entire experiment without PyCaret would have taken well over 100 lines of code in most libraries.\n",
    "\n",
    "We have only covered the basics of `pycaret.classification`. In the future tutorials we will go deeper into advanced pre-processing, ensembling, generalized stacking, and other techniques that allow you to fully customize your machine learning pipeline and are must know for any data scientist.\n",
    "\n",
    "Thank you for reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e88bd",
   "metadata": {},
   "source": [
    "## Important Links\n",
    " \n",
    "Tutorials: New to PyCaret? Check out our official notebooks\n",
    "\n",
    "https://github.com/pycaret/pycaret/tree/master/tutorials\n",
    "\n",
    "Example Notebooks: created by the community\n",
    "\n",
    "https://github.com/pycaret/pycaret/tree/master/examples\n",
    "\n",
    "Blog: Tutorials and articles by contributors\n",
    "\n",
    "https://github.com/pycaret/pycaret/tree/master/resources\n",
    "\n",
    "Documentation: The detailed API docs of PyCaret\n",
    "\n",
    "https://pycaret.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Video: Tutorials Our video tutorial from various events\n",
    "\n",
    "https://www.youtube.com/channel/UCxA1YTYJ9BEeo50lxyI_B3g\n",
    "\n",
    "Discussions: Have questions? Engage with community and contributors\n",
    "\n",
    "https://github.com/pycaret/pycaret/discussions\n",
    "\n",
    "Changelog: Changes and version history\n",
    "\n",
    "https://github.com/pycaret/pycaret/blob/master/CHANGELOG.md\n",
    "\n",
    "Roadmap: PyCaret’s software and community development plan\n",
    "\n",
    "https://github.com/pycaret/pycaret/issues/1756\n",
    "\n",
    "Bio: Moez Ali writes about PyCaret and its use-cases in the real world, If you would like to be notified automatically, you can follow Moez on Medium, LinkedIn, and Twitter.\n",
    "\n",
    "Original. Reposted with permission.\n",
    "\n",
    "https://towardsdatascience.com/introduction-to-binary-classification-with-pycaret-a37b3e89ad8d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecf520",
   "metadata": {},
   "source": [
    "## Related:\n",
    "\n",
    "A Beginner’s Guide to End to End Machine Learning\n",
    "\n",
    "https://www.kdnuggets.com/2021/12/beginner-guide-end-end-machine-learning.html\n",
    "\n",
    "PyCaret 2.3.5 Is Here! Learn What’s New\n",
    "\n",
    "https://www.kdnuggets.com/2021/11/pycaret-here-learn-new.html\n",
    "\n",
    "Using PyCaret’s New Time Series Module\n",
    "\n",
    "https://www.kdnuggets.com/2021/12/pycaret-new-time-series-module.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ababb470",
   "metadata": {},
   "source": [
    "## More On This Topic\n",
    "\n",
    "PyCaret 2.3.5 Is Here! Learn What’s New\n",
    "\n",
    "https://www.kdnuggets.com/2021/11/pycaret-here-learn-new.html\n",
    "\n",
    "Essential Data Science Tips: How to Use One-Vs-Rest and One-Vs-One…\n",
    "\n",
    "https://www.kdnuggets.com/2020/08/one-vs-rest-one-multi-class-classification.html\n",
    "\n",
    "5 Things You Don’t Know About PyCaret\n",
    "\n",
    "https://www.kdnuggets.com/2020/07/5-things-pycaret.html\n",
    "\n",
    "Announcing PyCaret 2.0\n",
    "\n",
    "https://www.kdnuggets.com/2020/08/announcing-pycaret-2.html\n",
    "\n",
    "Announcing PyCaret 1.0.0\n",
    "\n",
    "https://www.kdnuggets.com/2020/04/announcing-pycaret.html\n",
    "\n",
    "5 Things You Are Doing Wrong in PyCaret\n",
    "\n",
    "https://www.kdnuggets.com/2020/11/5-things-doing-wrong-pycaret.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
